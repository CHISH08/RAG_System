services:
  ollama:
    image: ollama/ollama
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - OLLAMA_LOAD_TIMEOUT=30m
    ports:
      - "11435:11434"
    volumes:
      - ollama:/root/.ollama
    entrypoint: >
      /bin/bash -c "
      (ollama serve &) &&
      sleep 5 &&
      ollama pull hf.co/bartowski/Qwen2.5.1-Coder-7B-Instruct-GGUF:IQ4_XS &&
      tail -f /dev/null
      "
    networks:
      - rag_network

networks:
  rag_network:
    driver: bridge

volumes:
  ollama:
